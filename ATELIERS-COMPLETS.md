# ğŸ“ Liste ComplÃ¨te des Ateliers - Stack d'ObservabilitÃ© Grafana

## ğŸ“š Vue d'Ensemble

Cette stack d'observabilitÃ© complÃ¨te couvre **tous les aspects** du monitoring moderne : mÃ©triques, logs, traces, et alerting. Voici la liste exhaustive des ateliers disponibles basÃ©s sur les composants dÃ©ployÃ©s.

---

## ğŸ—“ï¸ JOUR 1 : Fondamentaux Grafana et Datasources

### ğŸ“ Atelier 1 : Introduction Ã  Grafana (1h30)
**ğŸ“ ThÃ©orie + DÃ©mo**

**Contenu :**
- ğŸ—ï¸ Architecture et philosophie Grafana
- ğŸ“Š Comparaison OSS vs Enterprise vs Cloud
- ğŸ”‘ FonctionnalitÃ©s clÃ©s (Dashboards, Alerting, Plugins)
- ğŸ¯ Positionnement dans l'Ã©cosystÃ¨me d'observabilitÃ©
- ğŸ’¡ Use cases et bonnes pratiques

**Livrables :**
- âœ… ComprÃ©hension de l'architecture
- âœ… Quiz de validation
- âœ… Documentation de rÃ©fÃ©rence

---

### ğŸš€ Atelier 2 : Installation avec Docker Compose (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ“¦ DÃ©ploiement de la stack complÃ¨te
- âš™ï¸ Configuration du fichier .env
- ğŸ” SÃ©curisation des accÃ¨s
- ğŸ–¥ï¸ Navigation dans l'interface
- ğŸ› Troubleshooting courant

**Commandes ClÃ©s :**
```bash
# DÃ©marrer la stack
docker compose up -d

# VÃ©rifier les services
docker compose ps

# AccÃ©der Ã  Grafana
http://localhost:3000
```

**Livrables :**
- âœ… Stack opÃ©rationnelle
- âœ… AccÃ¨s Grafana configurÃ©
- âœ… Checklist de vÃ©rification

**ğŸ’¡ Tips :**
- Changez immÃ©diatement les mots de passe par dÃ©faut
- VÃ©rifiez les logs avec `docker compose logs`
- Utilisez `docker compose restart` en cas de problÃ¨me

---

### ğŸ—„ï¸ Atelier 3 : Datasource InfluxDB (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ“Š ModÃ¨le de donnÃ©es InfluxDB (Buckets, Measurements, Tags, Fields)
- ğŸ”Œ Configuration de la connexion
- ğŸ“ Langage Flux : requÃªtes basiques
- ğŸ“ˆ Visualisation de sÃ©ries temporelles

**Architecture InfluxDB :**
```
Organization (myorg)
â””â”€â”€ Bucket (payments)
    â””â”€â”€ Measurement (payment_transactions)
        â”œâ”€â”€ Tags: type, status, region
        â”œâ”€â”€ Fields: amount, fee, duration
        â””â”€â”€ Timestamp
```

**RequÃªtes Flux Essentielles :**
```flux
// Lire les donnÃ©es
from(bucket: "payments")
  |> range(start: -1h)
  |> filter(fn: (r) => r._measurement == "payment_transactions")

// AgrÃ©gation
from(bucket: "payments")
  |> range(start: -24h)
  |> filter(fn: (r) => r._field == "amount")
  |> aggregateWindow(every: 5m, fn: sum)

// Grouper par tag
from(bucket: "payments")
  |> range(start: -1h)
  |> group(columns: ["type"])
  |> sum()
```

**Livrables :**
- âœ… Datasource InfluxDB configurÃ©e
- âœ… DonnÃ©es de test crÃ©Ã©es
- âœ… RequÃªtes Flux fonctionnelles
- âœ… Premier panel de visualisation

**ğŸ› Troubleshooting :**
- **Connection refused** â†’ VÃ©rifier que InfluxDB est dÃ©marrÃ©
- **Unauthorized** â†’ VÃ©rifier le token dans .env
- **No data** â†’ CrÃ©er des donnÃ©es de test

---

### ğŸ“ˆ Atelier 4 : Datasource Prometheus (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ¯ Architecture Prometheus (Pull-based)
- ğŸ“Š ModÃ¨le de mÃ©triques (Counters, Gauges, Histograms)
- ğŸ” Langage PromQL
- ğŸ“‰ Visualisation de mÃ©triques systÃ¨me

**MÃ©triques Disponibles :**
- `up` : Statut des targets
- `http_requests_total` : Nombre de requÃªtes HTTP
- `http_request_duration_seconds` : Latence des requÃªtes
- `node_cpu_seconds_total` : Utilisation CPU
- `node_memory_MemAvailable_bytes` : MÃ©moire disponible

**RequÃªtes PromQL Essentielles :**
```promql
# MÃ©trique simple
http_requests_total

# Filtrer par label
http_requests_total{method="GET", status="200"}

# Rate (requÃªtes par seconde)
rate(http_requests_total[5m])

# AgrÃ©gation
sum by (method) (rate(http_requests_total[5m]))

# Taux d'erreur
(
  sum(rate(http_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_requests_total[5m]))
) * 100

# Percentile 95
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
)
```

**Livrables :**
- âœ… Datasource Prometheus configurÃ©e
- âœ… Exploration des targets
- âœ… RequÃªtes PromQL maÃ®trisÃ©es
- âœ… Dashboard de mÃ©triques systÃ¨me

**ğŸ’¡ Tips :**
- Utilisez `rate()` pour les counters
- AgrÃ©gez avec `sum()`, `avg()`, `max()`
- Filtrez avec `by` ou `without`
- Testez vos requÃªtes dans Prometheus UI (port 9090)

---

### ğŸ’¾ Atelier 5 : Datasource MS SQL Server (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ—„ï¸ Connexion Ã  MS SQL Server
- ğŸ“ RequÃªtes SQL pour Grafana
- ğŸ”„ Utilisation des macros Grafana
- ğŸ“Š Visualisation de donnÃ©es mÃ©tier

**Configuration :**
```yaml
Host: mssql:1433
Database: EBankingDB
User: sa
Password: EBanking@Secure123!
```

**RequÃªtes SQL pour Grafana :**
```sql
-- Time Series
SELECT 
    TransactionDate AS time,
    SUM(Amount) AS value,
    TransactionType AS metric
FROM Transactions
WHERE $__timeFilter(TransactionDate)
GROUP BY TransactionDate, TransactionType
ORDER BY time

-- AgrÃ©gation
SELECT 
    TransactionType,
    COUNT(*) AS count,
    SUM(Amount) AS total_amount,
    AVG(Amount) AS avg_amount
FROM Transactions
WHERE TransactionDate >= DATEADD(day, -7, GETDATE())
GROUP BY TransactionType

-- Avec variables Grafana
SELECT 
    TransactionDate AS time,
    Amount AS value
FROM Transactions
WHERE 
    $__timeFilter(TransactionDate)
    AND TransactionType = '$transaction_type'
ORDER BY time
```

**Macros Grafana :**
| Macro | Description |
|-------|-------------|
| `$__timeFrom()` | DÃ©but de la plage temporelle |
| `$__timeTo()` | Fin de la plage temporelle |
| `$__timeFilter(column)` | Filtre temporel complet |
| `$__interval` | Intervalle automatique |

**Livrables :**
- âœ… Datasource MS SQL configurÃ©e
- âœ… Base de donnÃ©es EBankingDB crÃ©Ã©e
- âœ… RequÃªtes SQL fonctionnelles
- âœ… Dashboard de donnÃ©es mÃ©tier

---

### ğŸ¯ Atelier 6 : Premier Dashboard Multi-Sources (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ“Š CrÃ©ation d'un dashboard complet
- ğŸ”„ Combinaison de plusieurs datasources
- ğŸ¨ Personnalisation des visualisations
- ğŸ’¾ Sauvegarde et partage

**Dashboard RecommandÃ© : "ObservabilitÃ© E-Banking"**

**Panel 1 : Transactions par Type (InfluxDB)**
```flux
from(bucket: "payments")
  |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
  |> filter(fn: (r) => r._measurement == "payment_transactions")
  |> filter(fn: (r) => r._field == "amount")
  |> group(columns: ["type"])
  |> aggregateWindow(every: 5m, fn: sum)
```
**Visualization:** Time Series

**Panel 2 : Taux de RequÃªtes API (Prometheus)**
```promql
sum by (status) (rate(http_requests_total[5m]))
```
**Visualization:** Graph

**Panel 3 : Top 10 Comptes (MS SQL)**
```sql
SELECT TOP 10
    AccountID,
    COUNT(*) AS transactions,
    SUM(Amount) AS total
FROM Transactions
WHERE $__timeFilter(TransactionDate)
GROUP BY AccountID
ORDER BY total DESC
```
**Visualization:** Table

**Livrables :**
- âœ… Dashboard multi-sources opÃ©rationnel
- âœ… Variables configurÃ©es
- âœ… Panels sauvegardÃ©s et organisÃ©s

---

## ğŸ—“ï¸ JOUR 2 : Logs, Traces et ObservabilitÃ© AvancÃ©e

### ğŸ“ Atelier 7 : Loki - AgrÃ©gation de Logs (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ“š Architecture Loki + Promtail
- ğŸ” LogQL : langage de requÃªte
- ğŸ¯ Filtrage et parsing de logs
- ğŸ“Š CorrÃ©lation logs â†” mÃ©triques

**Architecture :**
```
Applications â†’ Promtail â†’ Loki â†’ Grafana
```

**RequÃªtes LogQL :**
```logql
// Logs d'une application
{ServiceName="payment-api"}

// Filtrer par niveau
{ServiceName="payment-api"} |= "ERROR"

// Parser JSON
{ServiceName="payment-api"} | json | level="error"

// MÃ©triques depuis logs
sum(rate({ServiceName="payment-api"} |= "ERROR" [5m]))

// Logs d'une trace spÃ©cifique
{ServiceName="payment-api"} | json | trace_id="abc123"
```

**Livrables :**
- âœ… Loki + Promtail configurÃ©s
- âœ… Logs collectÃ©s et indexÃ©s
- âœ… RequÃªtes LogQL maÃ®trisÃ©es
- âœ… Dashboard de logs

**ğŸ’¡ Tips :**
- Utilisez des labels Ã  faible cardinalitÃ©
- Parsez les logs structurÃ©s (JSON)
- CorrÃ©lation avec traces via trace_id

---

### ğŸ” Atelier 8 : Tempo - Distributed Tracing (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ¯ Concepts du tracing distribuÃ©
- ğŸ”— OpenTelemetry et instrumentation
- ğŸ“Š Analyse de traces
- ğŸ”„ CorrÃ©lation traces â†” mÃ©triques â†” logs

**Architecture :**
```
Application (OpenTelemetry)
    â†“ OTLP (gRPC/HTTP)
Tempo (Storage)
    â†“
Grafana (Visualization)
```

**Protocoles SupportÃ©s :**
- **OTLP gRPC** : Port 4317
- **OTLP HTTP** : Port 4318
- **Zipkin** : Port 9411
- **Jaeger** : Port 14268

**API de Test :**
```bash
# GÃ©nÃ©rer une trace
curl http://localhost:8888/api/payment/process \
  -H "Content-Type: application/json" \
  -d '{"amount": 100, "currency": "EUR"}'

# VÃ©rifier dans Grafana Explore
# Query: {service.name="payment-api-instrumented"}
```

**RequÃªtes TraceQL :**
```traceql
// Toutes les traces d'un service
{service.name="payment-api-instrumented"}

// Traces avec erreurs
{service.name="payment-api-instrumented" && status=error}

// Traces lentes (> 1s)
{service.name="payment-api-instrumented" && duration > 1s}

// Filtrer par attribut
{service.name="payment-api-instrumented" && http.method="POST"}
```

**Livrables :**
- âœ… Tempo configurÃ©
- âœ… Application instrumentÃ©e
- âœ… Traces collectÃ©es
- âœ… Analyse de latence et erreurs
- âœ… CorrÃ©lation avec logs et mÃ©triques

**ğŸ› Troubleshooting :**
- VÃ©rifier les endpoints OTLP : `curl http://localhost:4318/v1/traces`
- Tester l'instrumentation : `docker compose logs payment-api_instrumented`
- VÃ©rifier les traces : http://localhost:3200

---

### ğŸ”” Atelier 9 : Alerting AvancÃ© (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸš¨ Configuration des rÃ¨gles d'alerte
- ğŸ“§ Canaux de notification (Email, Slack, Webhook)
- ğŸ”€ Politiques de routage
- ğŸ”• Silences et maintenance

**Architecture Alerting :**
```
Grafana Alert Rules
    â†“
Alert Manager
    â†“ (routing)
â”œâ”€ Email (Gmail SMTP)
â”œâ”€ Slack (Webhook)
â”œâ”€ PagerDuty
â””â”€ Custom Webhook
```

**RÃ¨gles d'Alerte PrÃ©-configurÃ©es :**

**1. Service Down**
```yaml
Condition: up == 0
Severity: Critical
Notification: Slack + Email
```

**2. High CPU**
```promql
avg(rate(node_cpu_seconds_total{mode!="idle"}[5m])) > 0.8
```
**Severity:** Warning

**3. High Error Rate**
```promql
(
  sum(rate(http_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_requests_total[5m]))
) > 0.05
```
**Severity:** Critical

**4. Database Connection Issues**
```sql
SELECT COUNT(*) FROM sys.dm_exec_connections
WHERE session_id > 50
HAVING COUNT(*) > 100
```

**Configuration Slack :**
```yaml
# grafana/provisioning/alerting/contactpoints.yaml
name: slack-notifications
type: slack
settings:
  url: https://hooks.slack.com/services/YOUR/WEBHOOK
  text: |
    ğŸš¨ {{ .CommonLabels.alertname }}
    Severity: {{ .CommonLabels.severity }}
    {{ .CommonAnnotations.description }}
```

**Configuration Email (Gmail) :**
```ini
# grafana/grafana.ini
[smtp]
enabled = true
host = smtp.gmail.com:587
user = your-email@gmail.com
password = your-app-password
from_address = your-email@gmail.com
```

**Livrables :**
- âœ… RÃ¨gles d'alerte configurÃ©es
- âœ… Canaux de notification testÃ©s
- âœ… Politiques de routage dÃ©finies
- âœ… Documentation des runbooks

**ğŸ’¡ Tips :**
- Ã‰vitez l'alert fatigue : alertez sur l'actionnable
- Utilisez des seuils adaptatifs
- Documentez les procÃ©dures de rÃ©solution
- Testez rÃ©guliÃ¨rement les notifications

---

### ğŸ“Š Atelier 10 : Dashboards AvancÃ©s (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ¨ Techniques de visualisation avancÃ©es
- ğŸ”„ Variables et templating
- ğŸ“ Transformations de donnÃ©es
- ğŸ”— Drill-down et navigation

**Techniques AvancÃ©es :**

**1. Variables Dashboard**
```
# Variable : Environment
Type: Query
Query (Prometheus): label_values(up, environment)

# Variable : Service
Type: Query
Query (Prometheus): label_values(up{environment="$environment"}, job)

# Utilisation dans requÃªte
up{environment="$environment", job="$service"}
```

**2. Transformations**
- **Merge** : Combiner plusieurs sÃ©ries
- **Filter by value** : Filtrer les valeurs
- **Organize fields** : RÃ©organiser les colonnes
- **Calculate field** : Calculer de nouvelles valeurs
- **Group by** : Regrouper les donnÃ©es

**3. Drill-Down**
```
# Panel 1 : Vue d'ensemble
Link: /d/detail-dashboard?var-service=$__field_labels.service

# Panel 2 : DÃ©tail du service
Affiche les mÃ©triques dÃ©taillÃ©es du service sÃ©lectionnÃ©
```

**4. Annotations**
```promql
# Annoter les dÃ©ploiements
ALERTS{alertname="DeploymentStarted"}
```

**Dashboard RecommandÃ© : "Golden Signals"**

**Panel 1 : Latency (P50, P95, P99)**
```promql
histogram_quantile(0.50, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

**Panel 2 : Traffic (Requests/sec)**
```promql
sum(rate(http_requests_total[5m]))
```

**Panel 3 : Errors (Error rate %)**
```promql
(
  sum(rate(http_requests_total{status=~"5.."}[5m]))
  /
  sum(rate(http_requests_total[5m]))
) * 100
```

**Panel 4 : Saturation (CPU, Memory)**
```promql
avg(rate(node_cpu_seconds_total{mode!="idle"}[5m]))
```

**Livrables :**
- âœ… Dashboard avec variables
- âœ… Transformations appliquÃ©es
- âœ… Navigation drill-down
- âœ… Annotations configurÃ©es

---

### ğŸ’¼ Atelier 11 : Monitoring E-Banking (2h)
**ğŸ› ï¸ Cas Pratique**

**Contenu :**
- ğŸ’° MÃ©triques mÃ©tier (Transactions, Comptes, Fraude)
- ğŸ“Š KPIs financiers
- ğŸ” DÃ©tection d'anomalies
- ğŸ“ˆ Reporting

**MÃ©triques E-Banking :**

**1. Transactions**
```flux
// Volume de transactions
from(bucket: "payments")
  |> range(start: -24h)
  |> filter(fn: (r) => r._measurement == "payment_transactions")
  |> filter(fn: (r) => r._field == "amount")
  |> aggregateWindow(every: 1h, fn: count)

// Montant moyen
from(bucket: "payments")
  |> range(start: -24h)
  |> filter(fn: (r) => r._field == "amount")
  |> mean()
```

**2. Taux de RÃ©ussite**
```sql
SELECT 
    CAST(TransactionDate AS DATE) AS date,
    COUNT(*) AS total_transactions,
    SUM(CASE WHEN Status = 'SUCCESS' THEN 1 ELSE 0 END) AS successful,
    (SUM(CASE WHEN Status = 'SUCCESS' THEN 1 ELSE 0 END) * 100.0 / COUNT(*)) AS success_rate
FROM Transactions
WHERE TransactionDate >= DATEADD(day, -30, GETDATE())
GROUP BY CAST(TransactionDate AS DATE)
ORDER BY date
```

**3. DÃ©tection de Fraude**
```sql
-- Transactions suspectes (montant Ã©levÃ© + frÃ©quence)
SELECT 
    AccountID,
    COUNT(*) AS transaction_count,
    SUM(Amount) AS total_amount,
    MAX(Amount) AS max_amount
FROM Transactions
WHERE 
    TransactionDate >= DATEADD(hour, -1, GETDATE())
    AND Amount > 1000
GROUP BY AccountID
HAVING COUNT(*) > 5
ORDER BY total_amount DESC
```

**4. SLA Monitoring**
```promql
# DisponibilitÃ© du service (SLA 99.9%)
avg_over_time(up{job="payment-api"}[30d]) * 100

# Latence P95 < 500ms
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket{job="payment-api"}[5m])
) < 0.5
```

**Dashboard : "E-Banking Overview"**
- ğŸ’° Volume de transactions (24h)
- ğŸ“Š Taux de rÃ©ussite (%)
- ğŸš¨ Alertes actives
- ğŸ“ˆ Tendances (7 jours)
- ğŸ” Transactions suspectes
- â±ï¸ Latence P95
- ğŸ’¾ Utilisation des ressources

**Livrables :**
- âœ… Dashboard E-Banking complet
- âœ… Alertes mÃ©tier configurÃ©es
- âœ… DÃ©tection de fraude active
- âœ… Reporting automatisÃ©

---

## ğŸ—“ï¸ JOUR 3 : Optimisation et Production

### âš¡ Atelier 12 : Performance et Optimisation (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸš€ Optimisation des requÃªtes
- ğŸ’¾ Gestion du cache
- ğŸ“Š Downsampling et agrÃ©gation
- ğŸ”§ Tuning de la stack

**Optimisations InfluxDB :**
```flux
// âŒ Mauvais : Trop de donnÃ©es
from(bucket: "payments")
  |> range(start: -365d)
  |> filter(fn: (r) => r._measurement == "payment_transactions")

// âœ… Bon : AgrÃ©gation
from(bucket: "payments")
  |> range(start: -365d)
  |> filter(fn: (r) => r._measurement == "payment_transactions")
  |> aggregateWindow(every: 1d, fn: mean)
  |> limit(n: 1000)
```

**Optimisations Prometheus :**
```promql
# âŒ Mauvais : Haute cardinalitÃ©
http_requests_total{user_id=~".*"}

# âœ… Bon : AgrÃ©gation
sum by (method, status) (http_requests_total)
```

**Optimisations SQL :**
```sql
-- âŒ Mauvais : Scan complet
SELECT * FROM Transactions
WHERE TransactionDate >= '2024-01-01'

-- âœ… Bon : Index + Limite
SELECT TOP 1000 
    TransactionID, Amount, TransactionDate
FROM Transactions WITH (INDEX(IX_TransactionDate))
WHERE TransactionDate >= DATEADD(day, -7, GETDATE())
ORDER BY TransactionDate DESC
```

**Configuration Grafana :**
```ini
[dataproxy]
timeout = 30
keep_alive_seconds = 30

[caching]
enabled = true

[query_history]
enabled = true
```

**Livrables :**
- âœ… RequÃªtes optimisÃ©es
- âœ… Cache configurÃ©
- âœ… Performance amÃ©liorÃ©e
- âœ… Documentation des optimisations

---

### ğŸ” Atelier 13 : SÃ©curitÃ© et RBAC (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ‘¥ Gestion des utilisateurs et Ã©quipes
- ğŸ”’ Permissions et rÃ´les (RBAC)
- ğŸ”‘ Authentification (LDAP, OAuth, SAML)
- ğŸ›¡ï¸ SÃ©curisation des datasources

**RÃ´les Grafana :**
- **Viewer** : Lecture seule
- **Editor** : CrÃ©ation/modification de dashboards
- **Admin** : Administration complÃ¨te

**Configuration RBAC :**
```bash
# CrÃ©er une Ã©quipe
curl -X POST http://localhost:3000/api/teams \
  -H "Content-Type: application/json" \
  -u admin:password \
  -d '{"name": "DevOps Team"}'

# Assigner des permissions
curl -X POST http://localhost:3000/api/folders/1/permissions \
  -H "Content-Type: application/json" \
  -u admin:password \
  -d '{
    "items": [
      {"teamId": 1, "permission": 2}
    ]
  }'
```

**Livrables :**
- âœ… Utilisateurs et Ã©quipes crÃ©Ã©s
- âœ… Permissions configurÃ©es
- âœ… Authentification sÃ©curisÃ©e

---

### ğŸ“¦ Atelier 14 : Backup et Disaster Recovery (1h30)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸ’¾ Sauvegarde des dashboards
- ğŸ”„ Export/Import de configuration
- ğŸ—„ï¸ Backup des donnÃ©es
- ğŸš¨ Plan de reprise d'activitÃ©

**Backup Grafana :**
```bash
# Backup des dashboards
curl -X GET http://localhost:3000/api/search \
  -u admin:password | jq -r '.[].uid' | \
  while read uid; do
    curl -X GET "http://localhost:3000/api/dashboards/uid/$uid" \
      -u admin:password > "backup_$uid.json"
  done

# Backup des volumes Docker
docker run --rm \
  -v observability-stack_grafana_data:/data \
  -v $(pwd):/backup \
  alpine tar czf /backup/grafana-backup.tar.gz /data
```

**Livrables :**
- âœ… Scripts de backup automatisÃ©s
- âœ… ProcÃ©dure de restauration testÃ©e
- âœ… Plan de DR documentÃ©

---

### ğŸš€ Atelier 15 : DÃ©ploiement en Production (2h)
**ğŸ› ï¸ Pratique**

**Contenu :**
- ğŸŒ Configuration pour la production
- ğŸ”’ SSL/TLS avec reverse proxy
- ğŸ“Š Monitoring de la stack elle-mÃªme
- ğŸ“ˆ ScalabilitÃ© et haute disponibilitÃ©

**Architecture Production :**
```
Internet
    â†“
Nginx (Reverse Proxy + SSL)
    â†“
Grafana (HA - 2+ instances)
    â†“
â”œâ”€ Prometheus (HA)
â”œâ”€ Loki (HA)
â”œâ”€ Tempo (HA)
â””â”€ PostgreSQL (Primary + Replica)
```

**Configuration Nginx :**
```nginx
server {
    listen 443 ssl http2;
    server_name grafana.example.com;

    ssl_certificate /etc/ssl/certs/grafana.crt;
    ssl_certificate_key /etc/ssl/private/grafana.key;

    location / {
        proxy_pass http://grafana:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

**Livrables :**
- âœ… Configuration production
- âœ… SSL/TLS activÃ©
- âœ… Haute disponibilitÃ© configurÃ©e
- âœ… Documentation de dÃ©ploiement

---

## ğŸ“š Ressources et Documentation

### ğŸ”— Liens Utiles

| Ressource | URL | Description |
|-----------|-----|-------------|
| **Grafana Docs** | https://grafana.com/docs/ | Documentation officielle |
| **Prometheus** | https://prometheus.io/docs/ | Guide Prometheus |
| **InfluxDB** | https://docs.influxdata.com/ | Documentation InfluxDB |
| **Loki** | https://grafana.com/docs/loki/ | Guide Loki |
| **Tempo** | https://grafana.com/docs/tempo/ | Documentation Tempo |

### ğŸ“– Fichiers de la Stack

| Fichier | Description |
|---------|-------------|
| `docker-compose.yml` | Configuration complÃ¨te de la stack |
| `.env.example` | Template de configuration |
| `DEPLOYMENT-GUIDE.md` | Guide de dÃ©ploiement |
| `ALERTING-README.md` | Configuration des alertes |
| `OBSERVABILITY-DESIGN-PATTERNS.md` | Patterns d'observabilitÃ© |

### ğŸ¯ Checklist ComplÃ¨te

#### Jour 1
- [ ] Grafana installÃ© et accessible
- [ ] InfluxDB configurÃ© et testÃ©
- [ ] Prometheus configurÃ© et testÃ©
- [ ] MS SQL configurÃ© et testÃ©
- [ ] Premier dashboard crÃ©Ã©

#### Jour 2
- [ ] Loki et Promtail configurÃ©s
- [ ] Tempo et tracing opÃ©rationnels
- [ ] Alerting configurÃ© et testÃ©
- [ ] Dashboard avancÃ© crÃ©Ã©
- [ ] Monitoring E-Banking dÃ©ployÃ©

#### Jour 3
- [ ] Optimisations appliquÃ©es
- [ ] RBAC configurÃ©
- [ ] Backup automatisÃ©
- [ ] Configuration production prÃªte

---

## ğŸ‰ Conclusion

Cette formation complÃ¨te couvre **tous les aspects** d'une stack d'observabilitÃ© moderne :

âœ… **15 ateliers pratiques**  
âœ… **3 jours de formation intensive**  
âœ… **MÃ©triques, Logs, Traces**  
âœ… **Alerting et Dashboards**  
âœ… **Production-ready**  

**ğŸš€ Vous Ãªtes maintenant prÃªt Ã  dÃ©ployer et gÃ©rer une infrastructure d'observabilitÃ© complÃ¨te !**

---

**ğŸ“§ Support :** Consultez les fichiers README de chaque composant  
**ğŸ› Issues :** RÃ©fÃ©rez-vous aux sections Troubleshooting  
**ğŸ“š Documentation :** Tous les guides sont dans le rÃ©pertoire `observability-stack/`
